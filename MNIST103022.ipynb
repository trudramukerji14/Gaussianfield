{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIamYefZoQEUXK/OppKFye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trudramukerji14/Gaussianfield/blob/main/MNIST103022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an implementation of the model used in [\"Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions\"](https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf) using Pytorch. This is still an ongoing work in process as of 10/30/22 more updated versions of this implementation will follow. "
      ],
      "metadata": {
        "id": "pzvRBXXveeTx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RktpCbBoZQN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the MNIST training and test data:\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,                         \n",
        "    transform = ToTensor(), \n",
        "    download = True,            \n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data', \n",
        "    train = False, \n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FFsnIP8RobP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To ease computation we see if we can reduce the size of the training and test data set:\n",
        "\n",
        "nb_selected_train_data = 600\n",
        "nb_selected_test_data = 250\n",
        "print(train_data.data.shape)\n",
        "print(test_data.data.shape)\n",
        "#\n",
        "train_data.data = train_data.data[:nb_selected_train_data:,]\n",
        "train_data.targets = train_data.targets[:nb_selected_train_data:,]\n",
        "print(train_data.data.shape)\n",
        "print(train_data.targets.shape)\n",
        "\n",
        "\n",
        "\n",
        "test_data.data = test_data.data[:nb_selected_test_data:,]\n",
        "test_data.targets = test_data.targets[:nb_selected_test_data:,]\n",
        "print(test_data.data.shape)\n",
        "print(test_data.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iidmHygUYDcS",
        "outputId": "e7874e35-57f1-4f82-e248-56d3a31e5f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n",
            "torch.Size([500, 28, 28])\n",
            "torch.Size([500])\n",
            "torch.Size([200, 28, 28])\n",
            "torch.Size([200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To make this a binary classification problem, we seperate 0's and 1's\n",
        "train_subset_indices = ((train_data.targets == 0) + (train_data.targets == 1)).nonzero().view(-1)\n",
        "test_subset_indices = ((test_data.targets == 0) + (test_data.targets == 1)).nonzero().view(-1)\n",
        "\n",
        "train_data.data = train_data.data[train_subset_indices]\n",
        "train_data.targets = train_data.targets[train_subset_indices]\n",
        "test_data.data = test_data.data[test_subset_indices]\n",
        "test_data.targets = test_data.targets[test_subset_indices]\n"
      ],
      "metadata": {
        "id": "dbL-B3jrYVjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the weight matrix as $W$ whose $ij$ entries are given by \n",
        "$$w_{ij} = \\exp\\bigg(\\sum^{m}_{d=1} (x_{id}-x_{jd})^{2}/\\sigma^{2}_{d}\\bigg)$$\n",
        "So a naive approach would be to perform this for computation $N$ points of data $N^{2}$ times. We then can set $\\sigma$ to be the variable to be optimized with pytorch. "
      ],
      "metadata": {
        "id": "gS0Wb6-zXR80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#version of the above functions that takes sigma as an input\n",
        "\n",
        "def wtrain(i,j,sigma):\n",
        "   sigma2 = torch.square(sigma)\n",
        "   s = train_data.data[i]\n",
        "   t = train_data.data[j]\n",
        "   s = torch.flatten(s)\n",
        "   t = torch.flatten(t)\n",
        "   d = (s-t)/1000\n",
        "   d = d/sigma2\n",
        "   d = (torch.norm(d))**2\n",
        "   d = torch.exp(-d)\n",
        "   return d\n",
        "\n",
        "def wtraintest(i,j, sigma):\n",
        "   sigma2 = torch.square(sigma)\n",
        "   s = train_data.data[i]\n",
        "   t = test_data.data[j]\n",
        "   s = torch.flatten(s)\n",
        "   t = torch.flatten(t)\n",
        "   d = (s-t)/1000\n",
        "   d = d/sigma2\n",
        "   d = (torch.norm(d))**2\n",
        "   d = torch.exp(-d)\n",
        "   return d\n",
        "\n",
        "def wtest(i,j,sigma):\n",
        "   sigma2 = torch.square(sigma)\n",
        "   s = test_data.data[i]\n",
        "   t = test_data.data[j]\n",
        "   s = torch.flatten(s)\n",
        "   t = torch.flatten(t)\n",
        "   d = (s-t)/1000\n",
        "   d = d/sigma2\n",
        "   d = (torch.norm(d))**2\n",
        "   d = torch.exp(-d)\n",
        "   return d\n",
        "\n"
      ],
      "metadata": {
        "id": "IXgL6uT1UodQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = (np.array(list(train_subset_indices)))\n",
        "Ntrain = xtrain.size\n",
        "xtest = (np.array(list(test_subset_indices)))\n",
        "Ntest = xtest.size\n",
        "xtrain = np.arange(Ntrain)\n",
        "xtest = np.arange(Ntest)\n",
        "\n",
        "\n",
        "\n",
        "def Wuu(sigma):\n",
        "  A = torch.zeros((Ntest,Ntest))\n",
        "  for i in xtest:\n",
        "    for j in xtest:\n",
        "     A[i,j] = wtest(i,j,sigma)\n",
        "  return A\n",
        "\n",
        "def  Wlu(sigma):\n",
        "#Define Wlu:\n",
        "  A = torch.zeros((Ntrain,Ntest))\n",
        "  for i in xtrain:\n",
        "    for j in xtest:\n",
        "      A[i,j] = wtraintest(i,j,sigma)\n",
        "  return A\n",
        "\n",
        "\n",
        "\n",
        "def Wll(sigma):\n",
        "#Define Wll:\n",
        "  A = torch.zeros((Ntrain, Ntrain))\n",
        "  for i in xtrain:\n",
        "    for j in xtrain:\n",
        "      A[i,j] = wtrain(i,j,sigma)\n",
        "  return A\n",
        "\n",
        "M = 28*28\n",
        "sigma = np.ones(M)\n",
        "sigma = Variable(torch.tensor(sigma), requires_grad=True)\n",
        "\n",
        "\n",
        "#Define W:\n",
        "def W(sigma):\n",
        "  A = Wll(sigma)\n",
        "  B = Wlu(sigma)\n",
        "  C = torch.t(B)\n",
        "  D = Wuu(sigma)\n",
        "  Wl = torch.cat([A,B], dim = 1 ) #Wl = np.block([Wll, Wlu])\n",
        "  Wu = torch.cat([C,D], dim = 1 ) #Wu = np.block([Wul, Wuu])\n",
        "  W = torch.cat([Wl, Wu], dim = 0) #W = np.block([[Wl],[Wu]])\n",
        "  return W\n",
        "\n",
        "def Duu(sigma):\n",
        "  A = W(sigma)\n",
        "  diagonal = torch.sum(A, axis = 1)\n",
        "  diagonalu = diagonal[-Ntest:]\n",
        "  A = torch.diag(diagonalu)\n",
        "  return A\n",
        "\n",
        "def operator(sigma):\n",
        "  A = Duu(sigma)\n",
        "  B = Wuu(sigma)\n",
        "  A = A-B\n",
        "  A = torch.linalg.inv(A)\n",
        "  return A\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def groundstate(sigma):\n",
        "  train_data.targets = train_data.targets.type(torch.FloatTensor)\n",
        "  B = Wlu(sigma)\n",
        "  C = torch.t(B)\n",
        "  fl = np.array(list(train_data.targets))\n",
        "  fl = torch.from_numpy(fl)\n",
        "  A = operator(sigma)\n",
        "  fu = torch.matmul(C, fl)\n",
        "  fu = torch.matmul(A,fu)\n",
        "  return fu\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hfQzN1Tu8NR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to check this\n",
        "\n",
        "Xuu = Wuu(sigma)\n",
        "#print(Wuu.shape)\n",
        "Xlu = Wlu(sigma)\n",
        "print(Xlu.shape)\n",
        "Xul = torch.t(Xlu)\n",
        "print(Xul.shape)\n",
        "Xll = Wll(sigma)\n",
        "print(Xll.shape)\n",
        "X = W(sigma)\n",
        "X = Duu(sigma)\n",
        "X = operator(sigma)\n",
        "xu = groundstate(sigma)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ-VlBEULd3M",
        "outputId": "dec4d428-02a0-43b6-8c82-96b94975124b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([116, 45])\n",
            "torch.Size([45, 116])\n",
            "torch.Size([116, 116])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xu.sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bluPXaIcfzO_",
        "outputId": "8b8ee3a8-c076-438f-87f4-2ccda8e91726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(40.1710, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost function used "
      ],
      "metadata": {
        "id": "7vUwolG7ftM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crossentropy(f,i):\n",
        "  x = -1*(f[i]*torch.log(f[i])+(1-f[i])*(torch.log(1-f[i])))\n",
        "  return x\n",
        "\n",
        "\n",
        "def averagelabelentropy(sigma):\n",
        "  f = groundstate(sigma)\n",
        "  N = len(f)\n",
        "  x = 0\n",
        "  for i in np.arange(len(f)):\n",
        "    x = x + crossentropy(f,i)\n",
        "    x = x/N\n",
        "  return x\n",
        "\n",
        "print(averagelabelentropy(sigma))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H37pV4qcRyGQ",
        "outputId": "4d9e5da2-6116-49d1-c313-71fbd77471ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0084, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the optimizer\n",
        "opt = torch.optim.Adam([sigma], lr=0.01)\n",
        "\n",
        "#number of steps in the optimization routine\n",
        "steps =  10\n",
        "\n",
        "# the final stage of optimization isn't always the best, so we keep track of\n",
        "# the best parameters along the way\n",
        "best_cost = averagelabelentropy(sigma)\n",
        "\n",
        "\n",
        "print(\"Cost after 0 steps is {:.4f}\".format(averagelabelentropy(sigma)))\n",
        "\n",
        "# optimization begins\n",
        "for n in range(steps):\n",
        "    opt.zero_grad()\n",
        "    loss = averagelabelentropy(sigma)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # keeps track of best parameters\n",
        "    if loss < best_cost \n",
        "        best_cost = loss\n",
        "        best_params = sigma\n",
        "\n",
        "    # Keep track of progress every 10 steps\n",
        "    if n % 10 == 9 or n == steps - 1:\n",
        "        print(\"Cost after {} steps is {:.4f}\".format(n + 1, loss))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-OZFKeoCRcCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926797e7-e309-43c2-a6c3-12554a3571d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after 0 steps is 0.0084\n",
            "Cost after 10 steps is 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_sigma = best_params\n",
        "xu = groundstate(best_sigma)\n",
        "print(xu)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trVX4GE3_Egi",
        "outputId": "227de78c-2f2c-4555-c620-950518d1e4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9938, 0.9104, 0.9926, 0.9441, 0.9156, 0.9905, 0.9035, 0.8261, 0.9934,\n",
            "        0.9927, 0.9928, 0.9914, 0.9931, 0.9926, 0.9294, 0.9934, 0.9529, 0.8776,\n",
            "        0.9931, 0.9933, 0.9918, 0.9911], grad_fn=<MvBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How do I count the 0's in the training data?\n",
        "\n",
        "#train_subset_indices = ((train_data.targets == 0) + (train_data.targets == 1)).nonzero().view(-1)\n",
        "\n",
        "train_zero_indices = (train_data.targets == 0).nonzero().view(-1)\n",
        "print(train_zero_indices)\n",
        "print(train_zero_indices.shape)\n",
        "Nzeros = np.array(list(train_zero_indices.shape)).sum()\n",
        "print(Nzeros)\n",
        "\n",
        "train_one_indices = (train_data.targets == 1).nonzero().view(-1)\n",
        "print(train_one_indices)\n",
        "print(train_one_indices.shape)\n",
        "Nones = np.array(list(train_one_indices.shape)).sum()\n",
        "print(Nones)\n",
        "\n",
        "q = Nones/(Nzeros + Nones)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(train_data.targets.shape)\n",
        "#print(test_data.data.shape)\n",
        "#print(test_data.targets.shape)\n",
        "#N = ((train_data.targets.shape)+ test_data.targets.shape)\n",
        "#print(N)\n",
        "#N = (np.array(list(N))).sum()\n",
        "#print(N)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNn3DAao_v7p",
        "outputId": "197f992f-05eb-4466-e089-b7e21cb70343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  0,   5,   8,   9,  11,  12,  14,  16,  17,  20,  23,  24,  25,  30,\n",
            "         33,  34,  35,  36,  41,  42,  46,  50,  52,  53,  55,  57,  59,  60,\n",
            "         61,  63,  65,  69,  71,  72,  73,  77,  78,  84,  90,  94,  95,  96,\n",
            "         97, 101, 102, 105, 106, 107, 110, 113])\n",
            "torch.Size([50])\n",
            "50\n",
            "tensor([  1,   2,   3,   4,   6,   7,  10,  13,  15,  18,  19,  21,  22,  26,\n",
            "         27,  28,  29,  31,  32,  37,  38,  39,  40,  43,  44,  45,  47,  48,\n",
            "         49,  51,  54,  56,  58,  62,  64,  66,  67,  68,  70,  74,  75,  76,\n",
            "         79,  80,  81,  82,  83,  85,  86,  87,  88,  89,  91,  92,  93,  98,\n",
            "         99, 100, 103, 104, 108, 109, 111, 112, 114, 115])\n",
            "torch.Size([66])\n",
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's assume that the proportion of ones to zeros in the training data is represented by $q$ and the proportion of zeros to ones in the training data is represented by $1-q$. We then classify a vertex $i$ if:   $$q \\frac{f_{u}(i)}{\\sum_{i} f_{u}(i)} > (1-q)\\frac{1-f_{u}(i)}{\\sum_{i}(1- f_{u}(i))}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "HaekL1hNKG6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(x):\n",
        "  N = len(x)\n",
        "  y = np.zeros(N)\n",
        "  sum = x.sum()\n",
        "  for i in np.arange(N):\n",
        "     LHS = q*(x[i]/sum) \n",
        "     RHS = (1-q)*((1-x[i])/(N-sum))\n",
        "     if LHS > RHS:\n",
        "       y[i] = 1\n",
        "     else:\n",
        "       y[i] = 0\n",
        "  return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XwlLQ-Y4PWne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(sigma):\n",
        "  x = groundstate(sigma)\n",
        "  y = classify(x)"
      ],
      "metadata": {
        "id": "YdkiUZvbB6aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xu[0]\n",
        "xu = groundstate(sigma)\n",
        "print(xu)\n",
        "print(q)\n",
        "classified = classify(xu)\n",
        "print(classified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxyCdrm8Rifz",
        "outputId": "e52d4f40-75be-4d42-df2e-7c48a455fef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9663, 0.7736, 0.9648, 0.8104, 0.7635, 0.9559, 0.7779, 0.6916, 0.9667,\n",
            "        0.9616, 0.9652, 0.9640, 0.9636, 0.9644, 0.8175, 0.9666, 0.8439, 0.6964,\n",
            "        0.9684, 0.9692, 0.9694, 0.9517, 0.7262, 0.9582, 0.8623, 0.9651, 0.7043,\n",
            "        0.9740, 0.9710, 0.9618, 0.7266, 0.9606, 0.8251, 0.9604, 0.9636, 0.9742,\n",
            "        0.9720, 0.8858, 0.7542, 0.9570, 0.9747, 0.9536, 0.8158, 0.6872, 0.9646],\n",
            "       grad_fn=<MvBackward0>)\n",
            "0.5689655172413793\n",
            "[1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = xu\n",
        "N = len(x)\n",
        "i = 0\n",
        "sum = x.sum()\n",
        "print(sum)\n",
        "LHS = q*(x[i]/sum)\n",
        "RHS = (1-q)*((1-x[i])/(N-sum))\n",
        "print(LHS,RHS)\n",
        "\n",
        "plt.imshow(test_data.data[i], cmap='gray')\n",
        "plt.title('%i' % test_data.targets[i])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "yNGjjnugTmeE",
        "outputId": "0b196fd4-3429-42fd-d79c-83f932f834d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19.7123, grad_fn=<SumBackward0>)\n",
            "tensor(0.0281, grad_fn=<MulBackward0>) tensor(0.0052, grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.targets)\n",
        "t = test_data.targets\n",
        "t = torch.Tensor.numpy(t)\n",
        "classified-t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWGCkoT_Cauz",
        "outputId": "31413939-ecc7-45a7-b1fd-6f195e0c1f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
            "        0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}